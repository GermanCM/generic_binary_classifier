{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"attempted relative import with no known parent package","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f50de1f365dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_classifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mds_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"]}],"source":["from modelling import binary_classifier as ds_classifier\n","import numpy as np\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.dummy import DummyClassifier"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from dataset_preprocessing import preprocessing as ds_prep\n","from tqdm import tqdm\n","from dataset_EDA import eda as ds_eda\n","from dataset_elt import dataset_extraction as ds_ext\n","import logging\n","\n","logging.basicConfig(filename='classifier.log',\n","                    level=logging.INFO, \n","                    format='%(asctime)s %(message)s')\n","logger = logging.getLogger(\"Dataset_eda\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Load dataset:"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":"\"\\nprecipitations_df = ds_extractor.load_dataset(ontology_name=ontology, \\n                                              columns_names=columns_names, \\n                                              desired_query_base=None, \\n                                              limit_rows_number=5000, \\n                                              ontology_first_level_name=None, \\n                                              ontology_items_field_name='items')\\n\""},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset_location = r'.\\datasets\\precipitations_df.csv'\n","\n","ds_extractor = ds_ext.Dataset_extraction(dataset_location)\n","\n","ontology = \"predictionmodel\"\n","columns_names = ['tmp0', 'tmp1', 'hPa', 'hum', 'pp']\n","limit_rows_number = 5000\n","# csv mode\n","ds_extractor.dataset_location = dataset_location\n","precipitations_df = ds_extractor.load_dataset(csv_mode=True, separator=',')\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tmp0</th>\n      <th>tmp1</th>\n      <th>hPa</th>\n      <th>hum</th>\n      <th>pp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>39.89</td>\n      <td>51.48</td>\n      <td>1092.0</td>\n      <td>0.93</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>7.20</td>\n      <td>7.01</td>\n      <td>936.0</td>\n      <td>0.57</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>18.55</td>\n      <td>20.12</td>\n      <td>981.0</td>\n      <td>0.66</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>16.77</td>\n      <td>16.77</td>\n      <td>1053.0</td>\n      <td>0.61</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>41.30</td>\n      <td>35.17</td>\n      <td>1018.0</td>\n      <td>0.14</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    tmp0   tmp1     hPa   hum   pp\n0  39.89  51.48  1092.0  0.93  0.0\n1   7.20   7.01   936.0  0.57  0.0\n2  18.55  20.12   981.0  0.66  0.0\n3  16.77  16.77  1053.0  0.61  0.0\n4  41.30  35.17  1018.0  0.14  0.0"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["precipitations_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n","precipitations_df.head()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Exploratory Data Analysis (EDA) steps:\n","    - a first view on the dataframe content: length, some of the first and\n","      last rows\n","    - generation of a profile report in HTML format, containing exploratory\n","      analysis info\n","      likeattributes correlations, descriptive statistics values, Pearson's\n","      correlation matrix,\n","      outlier detections, missing values detections...\n","    - custom functions to get this info per atribute"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["eda_obj = ds_eda.Dataset_eda(precipitations_df)\n","df_length, head_df, tail_df = eda_obj.check_dataframe_content()\n"]},{"cell_type":"markdown","metadata":{},"source":["eda_obj.profile_dataframe(\n","    output_file_location_name=\".\\\\dataset_EDA\\\\eda_reports\\\\ \\\n","                               precipitations_dataset_eda_report.html\")\n"," Attributes discarded due to high correlation over a defined threshold: 0,9"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":"Index(['tmp0', 'tmp1', 'hPa', 'hum', 'pp'], dtype='object')"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["rejected_attrs = eda_obj.get_rejected_attributes(correlation_threshold=0.9)\n","if rejected_attrs is not None:\n","  precipitations_df.drop(rejected_attrs, axis=1, inplace=True)\n","precipitations_df.columns\n"]},{"cell_type":"markdown","metadata":{},"source":[" Check for any missing values\n","    If there is a row with more than 50% of the attributes with missing values,\n","    drop the row.\n","    Otherwise, impute the missing value in that attribute."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":"Int64Index([], dtype='int64')"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["row_indexes_to_delete = eda_obj.check_row_indexes_to_delete(0.5)\n","row_indexes_to_delete\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 5/5 [00:00<00:00, 1672.10it/s]\n"},{"data":{"text/plain":"{}"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","  And now, we check for each attribute, any possible missing values\n","\"\"\"\n","attributes_missing_counts_dict = {}\n","for attribute in tqdm(precipitations_df.columns):\n","    attribute_missing_sub_df = eda_obj.check_for_missing_values(attribute)\n","    if attribute_missing_sub_df is not None:\n","        attributes_missing_counts_dict[attribute] = len(\n","            attribute_missing_sub_df)\n","\n","attributes_missing_counts_dict"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["ds_preprocessor = ds_prep.Preprocessing(precipitations_df)\n","attributes_names = precipitations_df.columns[:-1]\n","target_name = precipitations_df.columns[-1]\n","ds_bin_classifier = ds_classifier.Binary_classifier(\n","    precipitations_df, attributes_names, target_name)\n","# let's make our target attribute binary:\n","precipitations_df[target_name] = ds_preprocessor.binarize_target_variable(\n","    precipitations_df[target_name])\n","precipitations_df[target_name] = precipitations_df[target_name].apply(\n","    lambda x: np.int(x))\n","\n","ds_preprocessor = ds_prep.Preprocessing(precipitations_df)\n",""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["X_train, X_validation, y_train, y_validation = ds_bin_classifier.split_into_train_validation_sets(0.3)\n",""]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["X_train_scaled = ds_preprocessor.standard_scaler_transformer(\n","    X_train, X_train.columns)\n","X_train = None\n",""]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#X_validation_scaled = ds_preprocessor.standard_scaler_transformer(X_validation, X_validation.columns)\n","import pickle\n","\n","X_validation_scaled = pickle.load(open(\"preprocessor_scaler.pickle\", \"rb\"))\n","X_validation_scaled = X_validation_scaled.transform(X_validation.values) \n","X_validation = None\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["models_and_params = {'DummyClassifier': {'strategy': ['most_frequent']},\n","                     'GaussianNB': {'var_smoothing': [1e-09, 1e-08, 1e-10]},\n","                     'LogisticRegression': {'solver': ['liblinear'],\n","                                            'penalty': ['l1', 'l2'],\n","                                            'C': [1, 0.1, 0.01]},\n","                     'SVC': {'C': [1, 0.1, 0.01], 'gamma': ['scale', 'auto'],\n","                             'class_weight': ['balanced']}}\n","\n","Dummy_clf = DummyClassifier()\n","GaussianNB_clf = GaussianNB()\n","LogisticRegression_clf = LogisticRegression()\n","SVC_clf = SVC()\n","models_list = [Dummy_clf, GaussianNB_clf, LogisticRegression_clf, SVC_clf]\n",""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 4/4 [00:16<00:00,  4.03s/it]\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>mean_score_time</th>\n      <th>mean_test_f1</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_roc_auc</th>\n      <th>mean_train_f1</th>\n      <th>mean_train_recall</th>\n      <th>mean_train_roc_auc</th>\n      <th>param_C</th>\n      <th>param_class_weight</th>\n      <th>...</th>\n      <th>split9_train_recall</th>\n      <th>split9_train_roc_auc</th>\n      <th>std_fit_time</th>\n      <th>std_score_time</th>\n      <th>std_test_f1</th>\n      <th>std_test_recall</th>\n      <th>std_test_roc_auc</th>\n      <th>std_train_f1</th>\n      <th>std_train_recall</th>\n      <th>std_train_roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000804</td>\n      <td>0.001693</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000402</td>\n      <td>0.000468</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>0.001586</td>\n      <td>0.003103</td>\n      <td>0.715866</td>\n      <td>0.820274</td>\n      <td>0.962350</td>\n      <td>0.712704</td>\n      <td>0.819779</td>\n      <td>0.963659</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.815476</td>\n      <td>0.962678</td>\n      <td>0.000487</td>\n      <td>0.000297</td>\n      <td>0.030739</td>\n      <td>0.038590</td>\n      <td>0.006618</td>\n      <td>0.004652</td>\n      <td>0.004289</td>\n      <td>0.000767</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.001592</td>\n      <td>0.003083</td>\n      <td>0.715866</td>\n      <td>0.820274</td>\n      <td>0.962350</td>\n      <td>0.712704</td>\n      <td>0.819779</td>\n      <td>0.963659</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.815476</td>\n      <td>0.962678</td>\n      <td>0.000496</td>\n      <td>0.000532</td>\n      <td>0.030739</td>\n      <td>0.038590</td>\n      <td>0.006618</td>\n      <td>0.004652</td>\n      <td>0.004289</td>\n      <td>0.000767</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.001797</td>\n      <td>0.003095</td>\n      <td>0.715866</td>\n      <td>0.820274</td>\n      <td>0.962350</td>\n      <td>0.712704</td>\n      <td>0.819779</td>\n      <td>0.963659</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.815476</td>\n      <td>0.962678</td>\n      <td>0.000400</td>\n      <td>0.000299</td>\n      <td>0.030739</td>\n      <td>0.038590</td>\n      <td>0.006618</td>\n      <td>0.004652</td>\n      <td>0.004289</td>\n      <td>0.000767</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>0.052071</td>\n      <td>0.002982</td>\n      <td>0.929045</td>\n      <td>0.935611</td>\n      <td>0.998245</td>\n      <td>0.929379</td>\n      <td>0.936849</td>\n      <td>0.998347</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.931548</td>\n      <td>0.998162</td>\n      <td>0.001764</td>\n      <td>0.000018</td>\n      <td>0.030130</td>\n      <td>0.052537</td>\n      <td>0.001186</td>\n      <td>0.003615</td>\n      <td>0.003462</td>\n      <td>0.000137</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.003892</td>\n      <td>0.002995</td>\n      <td>0.907505</td>\n      <td>0.873846</td>\n      <td>0.998097</td>\n      <td>0.916760</td>\n      <td>0.887698</td>\n      <td>0.998209</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.869048</td>\n      <td>0.998067</td>\n      <td>0.000188</td>\n      <td>0.000017</td>\n      <td>0.050129</td>\n      <td>0.081834</td>\n      <td>0.001347</td>\n      <td>0.005262</td>\n      <td>0.010399</td>\n      <td>0.000154</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.011985</td>\n      <td>0.002672</td>\n      <td>0.893969</td>\n      <td>0.841707</td>\n      <td>0.997745</td>\n      <td>0.891497</td>\n      <td>0.836162</td>\n      <td>0.997812</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.815476</td>\n      <td>0.997678</td>\n      <td>0.000782</td>\n      <td>0.000458</td>\n      <td>0.048197</td>\n      <td>0.078630</td>\n      <td>0.001320</td>\n      <td>0.006610</td>\n      <td>0.011475</td>\n      <td>0.000176</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.003100</td>\n      <td>0.002993</td>\n      <td>0.766155</td>\n      <td>0.632089</td>\n      <td>0.996068</td>\n      <td>0.771337</td>\n      <td>0.631214</td>\n      <td>0.995972</td>\n      <td>0.1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.625000</td>\n      <td>0.995846</td>\n      <td>0.000296</td>\n      <td>0.000444</td>\n      <td>0.087126</td>\n      <td>0.110846</td>\n      <td>0.001926</td>\n      <td>0.006744</td>\n      <td>0.010287</td>\n      <td>0.000270</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.003197</td>\n      <td>0.002859</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.955627</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.955856</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.954264</td>\n      <td>0.000388</td>\n      <td>0.000550</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.007955</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000877</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.002500</td>\n      <td>0.002687</td>\n      <td>0.040408</td>\n      <td>0.021408</td>\n      <td>0.982084</td>\n      <td>0.040264</td>\n      <td>0.020553</td>\n      <td>0.982538</td>\n      <td>0.01</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.017857</td>\n      <td>0.981664</td>\n      <td>0.000499</td>\n      <td>0.000456</td>\n      <td>0.053777</td>\n      <td>0.028690</td>\n      <td>0.004067</td>\n      <td>0.005399</td>\n      <td>0.002808</td>\n      <td>0.000472</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>0.040299</td>\n      <td>0.009762</td>\n      <td>0.795353</td>\n      <td>1.000000</td>\n      <td>0.996988</td>\n      <td>0.793835</td>\n      <td>1.000000</td>\n      <td>0.997929</td>\n      <td>1</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.997747</td>\n      <td>0.001020</td>\n      <td>0.000390</td>\n      <td>0.025371</td>\n      <td>0.000000</td>\n      <td>0.001903</td>\n      <td>0.004941</td>\n      <td>0.000000</td>\n      <td>0.000187</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.040238</td>\n      <td>0.009286</td>\n      <td>0.795353</td>\n      <td>1.000000</td>\n      <td>0.996997</td>\n      <td>0.793928</td>\n      <td>1.000000</td>\n      <td>0.997929</td>\n      <td>1</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.997741</td>\n      <td>0.000913</td>\n      <td>0.000475</td>\n      <td>0.025371</td>\n      <td>0.000000</td>\n      <td>0.001885</td>\n      <td>0.004849</td>\n      <td>0.000000</td>\n      <td>0.000187</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.066257</td>\n      <td>0.015161</td>\n      <td>0.668686</td>\n      <td>1.000000</td>\n      <td>0.993222</td>\n      <td>0.669906</td>\n      <td>1.000000</td>\n      <td>0.994252</td>\n      <td>0.1</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.994042</td>\n      <td>0.000999</td>\n      <td>0.000406</td>\n      <td>0.035746</td>\n      <td>0.000000</td>\n      <td>0.002935</td>\n      <td>0.005584</td>\n      <td>0.000000</td>\n      <td>0.000344</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.066105</td>\n      <td>0.015564</td>\n      <td>0.668686</td>\n      <td>1.000000</td>\n      <td>0.993239</td>\n      <td>0.669972</td>\n      <td>1.000000</td>\n      <td>0.994253</td>\n      <td>0.1</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.994050</td>\n      <td>0.000912</td>\n      <td>0.000475</td>\n      <td>0.035746</td>\n      <td>0.000000</td>\n      <td>0.002941</td>\n      <td>0.005541</td>\n      <td>0.000000</td>\n      <td>0.000338</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.140232</td>\n      <td>0.030084</td>\n      <td>0.520776</td>\n      <td>1.000000</td>\n      <td>0.978820</td>\n      <td>0.519544</td>\n      <td>1.000000</td>\n      <td>0.980037</td>\n      <td>0.01</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.979629</td>\n      <td>0.002188</td>\n      <td>0.001182</td>\n      <td>0.016398</td>\n      <td>0.000000</td>\n      <td>0.004389</td>\n      <td>0.001698</td>\n      <td>0.000000</td>\n      <td>0.000462</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.138767</td>\n      <td>0.030022</td>\n      <td>0.520776</td>\n      <td>1.000000</td>\n      <td>0.978828</td>\n      <td>0.519584</td>\n      <td>1.000000</td>\n      <td>0.980035</td>\n      <td>0.01</td>\n      <td>balanced</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.979654</td>\n      <td>0.001572</td>\n      <td>0.001119</td>\n      <td>0.016398</td>\n      <td>0.000000</td>\n      <td>0.004422</td>\n      <td>0.001640</td>\n      <td>0.000000</td>\n      <td>0.000453</td>\n    </tr>\n  </tbody>\n</table>\n<p>16 rows × 87 columns</p>\n</div>","text/plain":"   mean_fit_time  mean_score_time  mean_test_f1  mean_test_recall  \\\n0       0.000804         0.001693      0.000000          0.000000   \n0       0.001586         0.003103      0.715866          0.820274   \n1       0.001592         0.003083      0.715866          0.820274   \n2       0.001797         0.003095      0.715866          0.820274   \n0       0.052071         0.002982      0.929045          0.935611   \n1       0.003892         0.002995      0.907505          0.873846   \n2       0.011985         0.002672      0.893969          0.841707   \n3       0.003100         0.002993      0.766155          0.632089   \n4       0.003197         0.002859      0.000000          0.000000   \n5       0.002500         0.002687      0.040408          0.021408   \n0       0.040299         0.009762      0.795353          1.000000   \n1       0.040238         0.009286      0.795353          1.000000   \n2       0.066257         0.015161      0.668686          1.000000   \n3       0.066105         0.015564      0.668686          1.000000   \n4       0.140232         0.030084      0.520776          1.000000   \n5       0.138767         0.030022      0.520776          1.000000   \n\n   mean_test_roc_auc  mean_train_f1  mean_train_recall  mean_train_roc_auc  \\\n0           0.500000       0.000000           0.000000            0.500000   \n0           0.962350       0.712704           0.819779            0.963659   \n1           0.962350       0.712704           0.819779            0.963659   \n2           0.962350       0.712704           0.819779            0.963659   \n0           0.998245       0.929379           0.936849            0.998347   \n1           0.998097       0.916760           0.887698            0.998209   \n2           0.997745       0.891497           0.836162            0.997812   \n3           0.996068       0.771337           0.631214            0.995972   \n4           0.955627       0.000000           0.000000            0.955856   \n5           0.982084       0.040264           0.020553            0.982538   \n0           0.996988       0.793835           1.000000            0.997929   \n1           0.996997       0.793928           1.000000            0.997929   \n2           0.993222       0.669906           1.000000            0.994252   \n3           0.993239       0.669972           1.000000            0.994253   \n4           0.978820       0.519544           1.000000            0.980037   \n5           0.978828       0.519584           1.000000            0.980035   \n\n  param_C param_class_weight  ... split9_train_recall split9_train_roc_auc  \\\n0     NaN                NaN  ...            0.000000             0.500000   \n0     NaN                NaN  ...            0.815476             0.962678   \n1     NaN                NaN  ...            0.815476             0.962678   \n2     NaN                NaN  ...            0.815476             0.962678   \n0       1                NaN  ...            0.931548             0.998162   \n1       1                NaN  ...            0.869048             0.998067   \n2     0.1                NaN  ...            0.815476             0.997678   \n3     0.1                NaN  ...            0.625000             0.995846   \n4    0.01                NaN  ...            0.000000             0.954264   \n5    0.01                NaN  ...            0.017857             0.981664   \n0       1           balanced  ...            1.000000             0.997747   \n1       1           balanced  ...            1.000000             0.997741   \n2     0.1           balanced  ...            1.000000             0.994042   \n3     0.1           balanced  ...            1.000000             0.994050   \n4    0.01           balanced  ...            1.000000             0.979629   \n5    0.01           balanced  ...            1.000000             0.979654   \n\n  std_fit_time std_score_time std_test_f1 std_test_recall  std_test_roc_auc  \\\n0     0.000402       0.000468    0.000000        0.000000          0.000000   \n0     0.000487       0.000297    0.030739        0.038590          0.006618   \n1     0.000496       0.000532    0.030739        0.038590          0.006618   \n2     0.000400       0.000299    0.030739        0.038590          0.006618   \n0     0.001764       0.000018    0.030130        0.052537          0.001186   \n1     0.000188       0.000017    0.050129        0.081834          0.001347   \n2     0.000782       0.000458    0.048197        0.078630          0.001320   \n3     0.000296       0.000444    0.087126        0.110846          0.001926   \n4     0.000388       0.000550    0.000000        0.000000          0.007955   \n5     0.000499       0.000456    0.053777        0.028690          0.004067   \n0     0.001020       0.000390    0.025371        0.000000          0.001903   \n1     0.000913       0.000475    0.025371        0.000000          0.001885   \n2     0.000999       0.000406    0.035746        0.000000          0.002935   \n3     0.000912       0.000475    0.035746        0.000000          0.002941   \n4     0.002188       0.001182    0.016398        0.000000          0.004389   \n5     0.001572       0.001119    0.016398        0.000000          0.004422   \n\n   std_train_f1  std_train_recall  std_train_roc_auc  \n0      0.000000          0.000000           0.000000  \n0      0.004652          0.004289           0.000767  \n1      0.004652          0.004289           0.000767  \n2      0.004652          0.004289           0.000767  \n0      0.003615          0.003462           0.000137  \n1      0.005262          0.010399           0.000154  \n2      0.006610          0.011475           0.000176  \n3      0.006744          0.010287           0.000270  \n4      0.000000          0.000000           0.000877  \n5      0.005399          0.002808           0.000472  \n0      0.004941          0.000000           0.000187  \n1      0.004849          0.000000           0.000187  \n2      0.005584          0.000000           0.000344  \n3      0.005541          0.000000           0.000338  \n4      0.001698          0.000000           0.000462  \n5      0.001640          0.000000           0.000453  \n\n[16 rows x 87 columns]"},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["cv_results_df, best_estimators_dict = \\\n","    ds_bin_classifier.select_model_via_grid_search_cv(models_list,\n","                                                    models_and_params,\n","                                                    X_train_scaled,\n","                                                    y_train.values,\n","                                                    cv_folds=10,\n","                                                    scoring_metrics=['recall',\n","                                                                     'f1',\n","                                                                     'roc_auc'],\n","                                                    refit_metric='roc_auc')\n","\n","cv_results_df\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":"{'DummyClassifier': DummyClassifier(constant=None, random_state=None, strategy='most_frequent'),\n 'GaussianNB': GaussianNB(priors=None, var_smoothing=1e-09),\n 'LogisticRegression': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n                    multi_class='warn', n_jobs=None, penalty='l1',\n                    random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                    warm_start=False),\n 'SVC': SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n     max_iter=-1, probability=False, random_state=None, shrinking=True,\n     tol=0.001, verbose=False)}"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["best_estimators_dict"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":"0.9982452271989014"},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["max_mean_test_roc_auc = cv_results_df['mean_test_roc_auc'].max()\n","max_mean_test_roc_auc"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>mean_score_time</th>\n      <th>mean_test_f1</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_roc_auc</th>\n      <th>mean_train_f1</th>\n      <th>mean_train_recall</th>\n      <th>mean_train_roc_auc</th>\n      <th>param_C</th>\n      <th>param_class_weight</th>\n      <th>...</th>\n      <th>split9_train_recall</th>\n      <th>split9_train_roc_auc</th>\n      <th>std_fit_time</th>\n      <th>std_score_time</th>\n      <th>std_test_f1</th>\n      <th>std_test_recall</th>\n      <th>std_test_roc_auc</th>\n      <th>std_train_f1</th>\n      <th>std_train_recall</th>\n      <th>std_train_roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.052071</td>\n      <td>0.002982</td>\n      <td>0.929045</td>\n      <td>0.935611</td>\n      <td>0.998245</td>\n      <td>0.929379</td>\n      <td>0.936849</td>\n      <td>0.998347</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.931548</td>\n      <td>0.998162</td>\n      <td>0.001764</td>\n      <td>0.000018</td>\n      <td>0.03013</td>\n      <td>0.052537</td>\n      <td>0.001186</td>\n      <td>0.003615</td>\n      <td>0.003462</td>\n      <td>0.000137</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 87 columns</p>\n</div>","text/plain":"   mean_fit_time  mean_score_time  mean_test_f1  mean_test_recall  \\\n0       0.052071         0.002982      0.929045          0.935611   \n\n   mean_test_roc_auc  mean_train_f1  mean_train_recall  mean_train_roc_auc  \\\n0           0.998245       0.929379           0.936849            0.998347   \n\n  param_C param_class_weight  ... split9_train_recall split9_train_roc_auc  \\\n0       1                NaN  ...            0.931548             0.998162   \n\n  std_fit_time std_score_time std_test_f1 std_test_recall  std_test_roc_auc  \\\n0     0.001764       0.000018     0.03013        0.052537          0.001186   \n\n   std_train_f1  std_train_recall  std_train_roc_auc  \n0      0.003615          0.003462           0.000137  \n\n[1 rows x 87 columns]"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","best_estimator_df, best_estimator_object = ds_bin_classifier.choose_best_estimator(cv_results_df, \n","                                                         'mean_test_roc_auc',\n","                                                         best_estimators_dict)\n","'''\n","max_mean_test_roc_auc = cv_results_df['mean_test_roc_auc'].max()\n","#print('best model: {}'.format(best_estimator_df[ 'mean_test_recall']))\n","best_model_info = cv_results_df[cv_results_df['mean_test_roc_auc']==max_mean_test_roc_auc]\n","best_model_info\n",""]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":"{'DummyClassifier': DummyClassifier(constant=None, random_state=None, strategy='most_frequent'),\n 'GaussianNB': GaussianNB(priors=None, var_smoothing=1e-09),\n 'LogisticRegression': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n                    multi_class='warn', n_jobs=None, penalty='l1',\n                    random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                    warm_start=False),\n 'SVC': SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n     decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n     max_iter=-1, probability=False, random_state=None, shrinking=True,\n     tol=0.001, verbose=False)}"},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["best_estimators_dict"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":"0    {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\nName: params, dtype: object"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["best_model_info.params"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":"LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l1',\n                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)"},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["best_estimators_dict['LogisticRegression']"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":"array([0], dtype=int64)"},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["selected_model = best_estimators_dict['LogisticRegression']\n","pickle.dump(selected_model, open(\"selected_model.pickle\", \"wb\"))\n","selected_model_loaded = pickle.load(open(\"selected_model.pickle\", \"rb\"))\n","selected_model_loaded.predict(X_validation_scaled[3].reshape(1, -1))\n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.7-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python_defaultSpec_1613990412003","display_name":"Python 3.7.7 64-bit ('base': conda)"}}}